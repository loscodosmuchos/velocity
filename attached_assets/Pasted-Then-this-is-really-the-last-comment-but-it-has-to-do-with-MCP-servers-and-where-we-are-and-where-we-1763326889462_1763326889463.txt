Then this is really the last comment but it has to do with MCP servers and where we are and where we're going. Us individually and us as an industry and industries across domains will be using MCP servers for facilitating the bridging of systems across all industries. And utilizing them to rapidly configure these connections, which will streamline all development using them. So our goal, knowing this, is to utilize the MCP server context and model as the framework for how we build this and everything else moving forward that requires external connections. Almost everything does. So what does that mean? That means in the context of this prompt that we are discussing now, collecting all of this information from different replets, applications we built and making a list of all of them, what they do, the best ones and a strategy for leveraging all that, bringing it out, creating a knowledge base and then being able to deploy them into different apps well that also means that we can convert them into services those modules and maybe that is the ultimate goal. Come to think of it maybe the ultimate goal really is to do the consolidation in the research part of it to figure out exactly what we got so all that stays the same but the end goal isn't to pace the modules into the replets. The end goal is to be able to ingest them or paste them into an MCP server so that the MCP server is serving those functions through MCP and so then the Replit apps themselves can be the three-stage base model right? Where it is the somewhat fixed input with file types and input methodologies to support the common you know doc csv excel markdown text file etc etc PDF those are the fixed ones we talked about then that passes off the homogenized data to the process in the middle which is what's doing the heavy lifting that is generative and requires flexibility processing accumulation tagging, categorization, formatting whatever it might be and then once it's done right? It passes it along to the export agent which then produces it in physical form or real world in a file form however in the specification that user has already set up with branding if applicable client or for style margin all of the output parameters their preferences, visuals, order, document numbers, tracking info and all of that to include source references and bibliography footnotes headers and all things that it could have. All the way down to page number or not if that's what you wanna get into. That granularity. However, in the middle, the middle could be the MCP piece. The beginning and end are largely the same. Once they're built and they're rock solid and they work great and they're integrated with the user authentication function so it's user auth function security it's robust AI capable flexible database optimized for Known integrations into AI, so using vector and other, uh, context-enhancing and preserving, respecting technologies. Innovative. Maximum insight capture generation metadata, something capable of embracing our entire philosophy which is spread across many different insight documents and things, which I know you have read and are familiar with. But, um... Base platform which will become the base for most of our apps moving forward which would be user authentication, user management portal in comms portal database for holding all the site and information and then the schema or the system that sits on top of that database that organizes captures ingest tags flags modifies. The information coming in and puts it where it's supposed to go on all the shelves per the documentation and we have all this stuff already spec'd out so those three things auth login security database and schema and then the piece in the middle is MCPs which could be served by this server that we're creating from all these replets so it could have 50 different functions and you just hit this MCP server press the function push the data in get it back out and move on and then we swap the modules out on the MCP server itself so it's modular in the way that it functions so everything is sort of encapsulated in its own little multi-tenant multimodal tenant setup and then we just it just builds a framework for building a module and then we can provide that to another system if it's not already in there and it can make it.