Yeah, I think a good way to put it, or a good way to look at it, is: Will we be exclaiming or explaining during the demo? Will we be exclaiming or explaining after we deploy this application? Are we exclaiming or explaining the features, functions, and capabilities of this application as related to the MVP specification that we need for our deployment?

In other words, are we deploying too soon, untested, unresearched, with not enough features to meet the need and an insufficient amount of care applied to the build, the solution, the components within it, and the level of attention and respect placed on the reality that a multi-billion dollar company will be giving us access to their most precious asset, which is their data and their network.

Thus, we are obligated and have a professional requirement, legally and personally and professionally, to safeguard their data and their trade secrets and the sanctity of our communications in relationship working together. So that needs to be front-and-center. We're not just making apps for entertainment, kids to play with on their iPad, that don't matter when we're another what happens with them. We're talking about a multi-billion dollar company with highly valuable data and tens of thousands of employees' jobs that depend on the safety and privacy of that data, as does our company and all those involved in its operation and funding and connection.

This is something we learn in through data recovery and electronic discovery litigation support services and many things I've done in the past. You know, chain of custody is important; there's a reason why it exists. It must be maintained, along with data sanitization from the ITAD world. Something I'm also very experienced in. I've worked a lot with within I know how companies feel about it, I know how they think about it, how they treat it in different industries. They think about it differently depending on what they do and what level of technical awareness they have and how they perceive themselves in relation to the data.

Our reverence and respect for them as professionals, as potential clients and partners, and appreciation for the opportunity because this is a big opportunity for us. If we can hit this out of the park and get evangelists that are exclaiming how wonderful this software has been and how it's helped them to solve their 200 project chaos or their procurement or vendor management issues, or get a handle on things that have been plaguing them for a while, then they will certainly be not only appreciative but they will become evangelists. They will tell all their colleagues who are in the same industry than other companies and within the company they'll tell their management which will then green light further deployment into other groups in the organization. That will give us this client as a testimonial. If you have this client as a testimonial, that will open the door to a number of other big clients we already have on the road map. But we got to have a successful deployment here and to do that we need to make sure that we're thinking about this through every angle and lens possible.

So that information about the sanctity and the importance of keeping top of mind that this isn't just about us. We're building this for them, so we have a responsibility and a professional obligation, and like I said, it's legal. If we make a mistake, you know, you have to have insurance, errors and omissions and professional insurance and whatnot. We used to have that at data recovery, so there are legal ramifications for not doing your homework and not doing due diligence, not following through, not completing QA and testing. Negligence that opens up security holes that someone else exploits means that the company or the developers are liable if they depended on AI to solve the problems and then AI said it did and it didn't and they didn't test that. That's on them, not on the AI. They're legally liable for that. I believe so. This is super credit unimportant. Keep it top of mind and top priority list for all developments. 